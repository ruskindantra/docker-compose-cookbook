version: '3'

services:
  zoo1:
    image: confluentinc/cp-zookeeper:6.2.1
    hostname: zoo1
    container_name: zoo1
    restart: unless-stopped
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zoo1:2888:3888;zoo2:2888:3888;zoo3:2888:3888
    volumes:
      - ./zookeeper-data/zoo1/data:/var/lib/zookeeper/data
      - ./zookeeper-data/zoo1/log:/var/lib/zookeeper/log

  zoo2:
    image: confluentinc/cp-zookeeper:6.2.1
    hostname: zoo2
    container_name: zoo2
    restart: unless-stopped
    ports:
      - "2182:2182"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2182
      ZOOKEEPER_SERVER_ID: 2
      ZOOKEEPER_SERVERS: zoo1:2888:3888;zoo2:2888:3888;zoo3:2888:3888
    volumes:
      - ./zookeeper-data/zoo2/data:/var/lib/zookeeper/data
      - ./zookeeper-data/zoo2/log:/var/lib/zookeeper/log

  zoo3:
    image: confluentinc/cp-zookeeper:6.2.1
    hostname: zoo3
    container_name: zoo3
    restart: unless-stopped
    ports:
      - "2183:2183"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2183
      ZOOKEEPER_SERVER_ID: 3
      ZOOKEEPER_SERVERS: zoo1:2888:3888;zoo2:2888:3888;zoo3:2888:3888
    volumes:
      - ./zookeeper-data/zoo3/data:/var/lib/zookeeper/data
      - ./zookeeper-data/zoo3/log:/var/lib/zookeeper/log

  zoo-navigator:
    image: elkozmon/zoonavigator:1.1.1
    hostname: zoo-navigator
    container_name: zoo-navigator
    restart: unless-stopped
    ports:
      - "9001:9001"
    environment:
      HTTP_PORT: 9001
      CONNECTION_LOCALZK_NAME: "Docker Zookeeper"
      CONNECTION_LOCALZK_CONN: zoo1:2181,zoo2:2182,zoo3:2183
    depends_on:
      - zoo1
      - zoo2
      - zoo3

  kafka1:
    image: confluentinc/cp-kafka:6.2.1
    container_name: kafka1
    restart: unless-stopped
    hostname: kafka1
    ports:
      - "9092:9092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka1:19092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
      KAFKA_BROKER_ID: 1
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    volumes:
      - ./kafka-data/kafka1/data:/var/lib/kafka/data

  kafka2:
    image: confluentinc/cp-kafka:6.2.1
    container_name: kafka2
    restart: unless-stopped
    hostname: kafka2
    ports:
      - "9093:9093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka2:19093,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
      KAFKA_BROKER_ID: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    volumes:
      - ./kafka-data/kafka2/data:/var/lib/kafka/data

  kafka3:
    image: confluentinc/cp-kafka:6.2.1
    container_name: kafka3
    restart: unless-stopped
    hostname: kafka3
    ports:
      - "9094:9094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka3:19094,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181,zoo2:2182,zoo3:2183"
      KAFKA_BROKER_ID: 3
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
    depends_on:
      - zoo1
      - zoo2
      - zoo3
    volumes:
      - ./kafka-data/kafka3/data:/var/lib/kafka/data

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - 8080:8080
    environment:
      - KAFKA_CLUSTERS_0_NAME=DockerCluster
      - KAFKA_CLUSTERS_0_ZOOKEEPER=zoo1:2181,zoo2:2182,zoo3:2183
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:19092,kafka2:19093,kafka3:19094
    depends_on:
      - zoo1
      - zoo2
      - zoo3
      - kafka1
      - kafka2
      - kafka3

  kafka-schema-registry:
    image: confluentinc/cp-schema-registry:6.2.2
    container_name: kafka-schema-registry
    restart: unless-stopped
    hostname: kafka-schema-registry
    depends_on:
      - zoo1
      - zoo2
      - zoo3
      - kafka1
      - kafka2
      - kafka3
    ports:
      - "8081:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: kafka-schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: 'PLAINTEXT://kafka1:19092,PLAINTEXT://kafka2:19093,PLAINTEXT://kafka3:19094'
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

  schema-registry-ui:
    image: landoop/schema-registry-ui:0.9.5
    container_name: schema-registry-ui
    restart: unless-stopped
    hostname: schema-registry-ui
    ports:
      - "8001:8000"
    environment:
      # Required. Instructs the UI where it can find the schema registry.
      SCHEMAREGISTRY_URL: http://kafka-schema-registry:8081/
      PROXY: "true"
    depends_on:
      - kafka-schema-registry

  kafka-connect:
    image: confluentinc/cp-kafka-connect:5.4.6
    container_name: kafka-connect
    restart: unless-stopped
    hostname: kafka-connect
    ports:
      - "8083:8083"
    environment:
      # Required.
      # The list of Kafka brokers to connect to. This is only used for bootstrapping,
      # the addresses provided here are used to initially connect to the cluster,
      # after which the cluster can dynamically change. Thanks, ZooKeeper!
      CONNECT_BOOTSTRAP_SERVERS: "kafka1:19092,kafka2:19093,kafka3:19094"
      # Required. A unique string that identifies the Connect cluster group this worker belongs to.
      CONNECT_GROUP_ID: compose-connect-group
      # Connect will actually use Kafka topics as a datastore for configuration and other data. #meta
      # Required. The name of the topic where connector and task configuration data are stored.
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      # Required. The name of the topic where connector and task configuration offsets are stored.
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      # Required. The name of the topic where connector and task configuration status updates are stored.
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      # Required. Converter class for key Connect data. This controls the format of the
      # data that will be written to Kafka for source connectors or read from Kafka for sink connectors.
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      # Allows connect to leverage the power of schema registry. Here we define it for key schemas.
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-schema-registry:8081'
      # Required. Converter class for value Connect data. This controls the format of the
      # data that will be written to Kafka for source connectors or read from Kafka for sink connectors.
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      # Allows connect to leverage the power of schema registry. Here we define it for value schemas.
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://kafka-schema-registry:8081'
      # Required. Converter class for internal key Connect data that implements the Converter interface.
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Required. Converter class for offset value Connect data that implements the Converter interface.
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Required. The hostname that will be given out to other workers to connect to.
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      # The next three are required when running in a single-node cluster, as we are.
      # We would be able to take the default (of 3) if we had three or more nodes in the cluster.
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "3"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "3"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "3"
    # kafka-connect relies upon Kafka and ZooKeeper.
    # This will instruct docker to wait until those services are up
    # before attempting to start kafka-connect.
    depends_on:
      - zoo1
      - zoo2
      - zoo3
      - kafka1
      - kafka2
      - kafka3

  kafka-connect-ui:
    image: landoop/kafka-connect-ui:0.9.7
    hostname: kafka-connect-ui
    container_name: kafka-connect-ui
    restart: unless-stopped
    ports:
      - "8002:8000"
    environment:
      CONNECT_URL: "http://kafka-connect:8083/"
      PROXY: "true"
    depends_on:
      - kafka-connect